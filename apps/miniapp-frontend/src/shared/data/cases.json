{
  "cases": [
    {
      "slug": "fintech-security-regulator-remediation",
      "title": "−58% критических уязвимостей за 10 недель в финтехе",
      "industry": "Финтех",
      "problem": "Финтех-компания (200+ сотрудников) готовилась к проверке регулятора и параллельно расширяла периметр: новые интеграции, удалённые рабочие места, отдельные сервисы для партнёров. Во время предварительной проверки нашли критические уязвимости: открытые админ-панели, слабые политики доступа, «дырявые» VPN-настройки.\n\nРаньше проблему пытались закрывать точечно: ставили отдельные средства защиты, «латали» самые громкие находки, но не было реестра активов и приоритетов. Логи хранились разрозненно, патчи устанавливались вручную, а инциденты разбирались постфактум.\n\nНа кону были не только штрафы и предписания, но и риск простоя платёжных сервисов. Для финтеха это прямые потери выручки и доверия: одна утечка или компрометация учёток стоит дороже, чем весь квартальный бюджет на ИБ.",
      "approach": "Начали с инженерной диагностики: инвентаризация активов, сканирование внешнего и внутреннего периметра, проверка конфигураций доступа и обзор процессов реагирования. Параллельно построили модель угроз и привязали риски к критичным бизнес-сервисам.\n\nРассматривали два пути: быстрое «закрытие дыр» без изменений процессов или развёртывание полноценного SOC сразу. Выбрали поэтапный вариант: сначала закрываем критические риски и вводим базовый контроль (логирование/алёрты), затем масштабируем мониторинг и регламенты.\n\nОграничения были жёсткие: производство нельзя останавливать, изменения — только в согласованные окна, а дедлайн по предписанию регулятора — 60 дней. Поэтому все меры проектировали с откатом и проверкой на стенде перед продом.",
      "solution": "За первые 2 недели закрыли «быстрые» критические точки: включили MFA для админ-доступа и VPN, убрали публичные админ-интерфейсы, обновили уязвимые компоненты в ключевых сервисах. Параллельно настроили базовую сегментацию доступа для критичных подсетей.\n\nДальше собрали единый контур мониторинга: централизовали логи VPN/IAM/серверов/приложений, настроили корреляционные правила и алёрты по подозрительным входам и аномалиям. На рабочих станциях и серверах внедрили EDR-покрытие для критических групп.\n\nЧтобы изменения не «умерли» после проекта, подготовили runbook, регламент инцидент-менеджмента и провели table-top тренировку. В конце — повторная проверка уязвимостей и отчёт по закрытию пунктов предписания с метриками покрытия и времени реакции.",
      "stack": [
        "Nessus",
        "Nmap",
        "Burp Suite",
        "Wazuh",
        "Elastic Stack",
        "Keycloak",
        "Kubernetes",
        "Ansible"
      ],
      "timeline": "10 недель",
      "metrics": {
        "headline": "−58% критических уязвимостей",
        "items": [
          {
            "label": "Критические уязвимости",
            "value": "17 → 7",
            "description": "Закрыли critical/high находки в периметре и ключевых сервисах по плану ремедиации."
          },
          {
            "label": "Время обнаружения инцидента (MTTD)",
            "value": "2–3 дня → 20 минут",
            "description": "Алёрты по аномальным логинам и событиям безопасности стали приходить автоматически."
          },
          {
            "label": "Покрытие логированием критических систем",
            "value": "35% → 85%",
            "description": "Собрали логи из VPN, IAM, приложений и серверов в единый контур мониторинга."
          },
          {
            "label": "Замечания регулятора",
            "value": "12 → 0",
            "description": "Закрыли все пункты предписания в согласованный срок и подтвердили повторной проверкой."
          }
        ],
        "testimonial": {
          "quote": "Мы получили карту рисков за 3 недели и понятный план, а затем закрыли критические пункты без простоя сервисов. Теперь видно, куда вкладывать бюджет ИБ.",
          "author": "CTO, финтех-компания (200+ чел.)"
        }
      },
      "assets": {
        "heroImage": "abstract fintech security risk dashboard, dark theme, deep blue primary with cyan accents, clean minimal UI, data visualization, network graph, 16:9",
        "beforeAfter": {
          "before": "Критические уязвимости были выявлены, но приоритетов и единого мониторинга не было.",
          "after": "Критические риски закрыты, есть SIEM-метрики, алёрты и регламент реагирования."
        }
      },
      "tags": [
        "fintech",
        "security-audit",
        "pdn-compliance",
        "penetration-testing",
        "siem"
      ],
      "relatedServiceSlugs": [
        "cybersecurity-audit-protection"
      ]
    },
    {
      "slug": "retail-returns-cycle-reduction",
      "title": "−57% времени возвратов за 2 месяца в ритейл-сети",
      "industry": "Ритейл",
      "problem": "Ритейл-сеть (50+ магазинов) обрабатывала в среднем 2 300 возвратов в месяц, но полный цикл занимал до 14 дней. Покупатели ждали деньги неделями, а магазины держали возвраты «в подвешенном состоянии» между кассой, складом и бухгалтерией.\n\nПопытки ускорить процесс были локальными: каждый регион делал свои правила, часть шагов фиксировали в Excel, статусы расходились между системами. IT-команда была перегружена, поэтому автоматизацию откладывали, а разбор «где зависло» занимал больше времени, чем сам возврат.\n\nНа кону были NPS и повторные покупки: задержки по возвратам напрямую били по лояльности. Плюс росли списания и замораживались деньги в товаре, который фактически уже вернулся, но не прошёл финансовое закрытие.",
      "approach": "Мы разобрали процесс end-to-end: магазин → склад/логистика → контроль качества → бухгалтерия. Сняли фактические времена по этапам, измерили очереди и причины возвратов, собрали «узкие места» и их стоимость в часах и рублях.\n\nРассматривали два варианта: купить отдельный модуль возвратов и ждать внедрения или сначала выровнять процесс и KPI, а IT-изменения делать точечно. Выбрали второй путь: быстрый реинжиниринг с едиными статусами и SLA, чтобы получить эффект в квартале, а не «когда-нибудь».\n\nОграничения: нельзя было останавливать продажи и менять ядро действующей ERP в сезон. Поэтому опирались на минимальные доработки и прозрачную дисциплину: единый тикет, роли (RACI), контроль сроков и стандартные чек-листы.",
      "solution": "Ввели единый «return ticket» и нормализовали статусы на всём пути — от кассы до бухгалтерии. Закрепили владельцев этапов, SLA по каждому шагу и правила эскалации при превышении сроков.\n\nСделали набор быстрых изменений: стандартные шаблоны документов, чек-листы контроля качества, централизованное согласование спорных возвратов. Построили дашборд контроля цикла и очередей на базе текущих данных, чтобы управлять процессом ежедневно.\n\nЗапустили пилот на 10 магазинах, отработали исключения и обучили персонал. После стабилизации — тиражирование на сеть и контроль метрик в течение 4 недель, чтобы эффект закрепился, а не «растворился».",
      "stack": [
        "BPMN 2.0",
        "Miro",
        "Power BI",
        "SQL",
        "Lean",
        "RACI",
        "Value Stream Mapping"
      ],
      "timeline": "8 недель",
      "metrics": {
        "headline": "14 дней → 6 дней",
        "items": [
          {
            "label": "Средний цикл возврата",
            "value": "14 дней → 6 дней",
            "description": "Убрали ожидание на согласованиях и выровняли правила по всей сети."
          },
          {
            "label": "Доля возвратов, закрытых за 7 дней",
            "value": "22% → 74%",
            "description": "Ввели SLA по этапам и ежедневный контроль очередей через дашборд."
          },
          {
            "label": "Ошибки в документах возврата",
            "value": "9,5% → 3,1%",
            "description": "Стандартизировали шаблоны и чек-листы, уменьшили количество переделок."
          },
          {
            "label": "Замороженные средства в возвратах",
            "value": "−18%",
            "description": "Ускорили финансовое закрытие и движение товара обратно в оборот."
          }
        ],
        "testimonial": {
          "quote": "Теперь видно, где именно «завис» возврат и кто отвечает за этап. За пару месяцев цикл сократился почти вдвое без тяжёлых IT-переделок.",
          "author": "COO, ритейл-сеть (50+ магазинов)"
        }
      },
      "assets": {
        "heroImage": "abstract retail returns workflow dashboard, clean minimal dark UI, deep blue with cyan accents, store network map, process timeline visualization, 16:9",
        "beforeAfter": {
          "before": "Возвраты шли разными маршрутами, средний цикл — 14 дней, статус часто терялся между командами.",
          "after": "Единый поток и SLA: средний цикл — 6 дней, статус прозрачен для магазина, склада и офиса."
        }
      },
      "tags": [
        "retail",
        "process-optimization",
        "kpi",
        "workflow",
        "bi-dashboard"
      ],
      "relatedServiceSlugs": [
        "process-optimization-audit-kpi"
      ]
    },
    {
      "slug": "logistics-crm-erp-wms-automation",
      "title": "−42% ручного ввода за 7 недель в логистической компании",
      "industry": "Логистика",
      "problem": "Логистическая компания (300+ сотрудников) обрабатывала ~1 600 отправок в день, а данные по заказам и статусам переносили вручную между CRM, ERP и складской системой (WMS). Шесть операторов тратили на это 3–4 часа в день, а ошибки в адресах и номенклатуре приводили к задержкам и штрафам.\n\nРаньше пытались «ускориться» Excel-шаблонами и скриптами, но они ломались при изменениях форматов и не покрывали исключения. У WMS не было полноценного API, а разработка интеграционной шины упиралась в бюджет и отсутствие выделенной команды.\n\nНа кону были сроки доставки и корректность счётов. Каждый неверный статус или накладная — это повторные звонки клиентов, переработки на складе и прямые финансовые потери.",
      "approach": "Начали с аудита потоков данных: какие поля где рождаются, кто их меняет и где возникает расхождение. Собрали реестр сценариев, оценили их ROI и выбрали 4 приоритетных — по объёму операций и стоимости ошибок.\n\nРассматривали два решения: строить полноценную интеграционную платформу (ESB) или использовать RPA как «мост» для legacy WMS. Выбрали гибрид: API-интеграция там, где это возможно, и RPA для участка без API, чтобы получить эффект за недели.\n\nОграничения: система работала 24/7, нельзя было ломать существующие процессы склада, а доступы должны были соответствовать требованиям ИБ. Поэтому сделали безопасные учётки роботов, контроль прав и обязательное логирование всех действий.",
      "solution": "Реализовали API-связку между CRM и ERP для создания заказов и передачи финансовых атрибутов. Для WMS, где API отсутствовал, внедрили RPA-роботов с устойчивыми сценариями и обработкой исключений.\n\nСобрали 4 робота: создание отгрузки в WMS, синхронизация статусов, формирование черновиков документов, сверка расхождений и постановка задач операторам по исключениям. Добавили очередь задач, ретраи и контроль дублей, чтобы автоматизация не портила данные.\n\nНастроили мониторинг выполнения сценариев, отчёты по ошибкам и runbook эксплуатации. Запускали по схеме «параллельный прогон → прод → контроль 2 недели», чтобы не останавливать отгрузки.",
      "stack": [
        "Robocorp",
        "Python",
        "FastAPI",
        "PostgreSQL",
        "RabbitMQ",
        "Grafana",
        "Sentry"
      ],
      "timeline": "7 недель",
      "metrics": {
        "headline": "−42% ручного труда",
        "items": [
          {
            "label": "Ручные операции ввода",
            "value": "≈ 520 ч/мес → 300 ч/мес",
            "description": "Автоматизировали переносы заказов и статусов между CRM, ERP и WMS."
          },
          {
            "label": "Ошибки в заказах и накладных",
            "value": "1,8% → 0,6%",
            "description": "Убрали человеческий фактор на ключевых полях и добавили проверки."
          },
          {
            "label": "Время от заказа до отгрузки",
            "value": "6,2 ч → 5,1 ч",
            "description": "Сократили задержки на ручных переносах и уточнениях данных."
          },
          {
            "label": "Срок окупаемости",
            "value": "4 месяца",
            "description": "Эффект рассчитали по экономии часов и снижению штрафов за ошибки в доставке."
          }
        ],
        "testimonial": {
          "quote": "Роботы закрыли самый неприятный участок — перенос данных между системами. Ошибки теперь видны сразу, а не на этапе доставки.",
          "author": "Руководитель операций, логистика (300+ чел.)"
        }
      },
      "assets": {
        "heroImage": "abstract logistics integration dashboard, data pipelines between CRM ERP WMS, clean minimal dark UI, deep blue with cyan highlights, flow lines, 16:9",
        "beforeAfter": {
          "before": "Операторы вручную переносили данные и статусы между CRM, ERP и складской системой.",
          "after": "Синхронизация автоматизирована, исключения попадают в очередь с контролем и логированием."
        }
      },
      "tags": [
        "logistics",
        "rpa",
        "system-integration",
        "workflow-automation",
        "roi"
      ],
      "relatedServiceSlugs": [
        "automation-rpa-crm-erp"
      ]
    },
    {
      "slug": "medtech-support-ai-triage",
      "title": "−31% времени обработки обращений за 9 недель в медтехе",
      "industry": "Медтех",
      "problem": "Медтех-компания в службе поддержки обрабатывала ~35 000 обращений в месяц, и около 70% из них были типовыми (статусы, доступ, инструкции, ошибки установки). Несмотря на это, классификация и подбор ответа делались вручную, из‑за чего росла очередь и нарушался SLA.\n\nРаньше пробовали FAQ и простого чат-бота на правилах, но он быстро устаревал и плохо покрывал вариативные формулировки. Данные по обращениям были «грязными»: дубли, разные шаблоны, отсутствующие поля, поэтому попытки автоматизации давали низкую точность.\n\nНа кону стояли удержание клиентов и комплаенс: часть обращений содержала персональные и медицинские данные. Нужно было ускорить обработку без риска утечек и без вывода данных за периметр.",
      "approach": "Начали с аудита тикетов: выделили 30 устойчивых категорий, оценили объём, сложность и экономику, настроили базовые правила очистки данных. Собрали baseline по точности, времени обработки и SLA до вмешательства.\n\nРассматривали два сценария: полноценный self‑service чат-бот для клиентов или agent-assist, который помогает оператору. Выбрали agent-assist как более управляемый и безопасный путь: оператор остаётся в контуре, а AI ускоряет маршрутизацию и подготовку ответа.\n\nОграничения: данные не должны покидать периметр, нужна трассируемость решений и понятный механизм отката. Поэтому заложили MLOps, мониторинг качества и «human-in-the-loop» — оператор подтверждает или исправляет подсказку.",
      "solution": "Построили NLP-классификатор обращений и извлечение сущностей (продукт, версия, ошибка, тип доступа). На входе тикет получает категорию, приоритет и предлагаемый маршрут на группу поддержки.\n\nСделали модуль подсказок ответа: поиск по базе знаний + шаблоны с подстановками, которые оператор подтверждает и отправляет. Интегрировали решение в сервис-деск, добавили сбор обратной связи (принял/исправил) для дообучения.\n\nРазвернули MLOps-контур: версионирование моделей, CI/CD, мониторинг точности и дрейфа, алёрты при падении качества. После запуска — обучение команды и runbook, чтобы поддержка могла работать с системой без зависимости от подрядчика.",
      "stack": [
        "Python",
        "FastAPI",
        "spaCy",
        "scikit-learn",
        "MLflow",
        "Docker",
        "Jira Service Management",
        "PostgreSQL"
      ],
      "timeline": "9 недель",
      "metrics": {
        "headline": "−31% времени обработки",
        "items": [
          {
            "label": "Среднее время обработки тикета",
            "value": "12,5 мин → 8,6 мин",
            "description": "Подсказки и автоклассификация сократили ручные шаги оператора."
          },
          {
            "label": "Время маршрутизации",
            "value": "6 мин → 1,5 мин",
            "description": "Категория и приоритет назначаются на входе, без ручного перебора очередей."
          },
          {
            "label": "Доля обращений, закрытых с первого контакта (FCR)",
            "value": "41% → 53%",
            "description": "Шаблоны ответов и поиск по базе знаний повысили точность первого ответа."
          },
          {
            "label": "Выполнение SLA по первому ответу",
            "value": "92% → 98%",
            "description": "Очередь стала предсказуемой, типовые вопросы обрабатываются быстрее."
          }
        ],
        "testimonial": {
          "quote": "Мы не заменяли операторов — мы убрали лишние ручные шаги. Типовые обращения теперь решаются за минуты, а сложные попадают сразу к нужной группе.",
          "author": "Руководитель поддержки, медтех-компания (200+ чел.)"
        }
      },
      "assets": {
        "heroImage": "abstract medtech customer support AI dashboard, dark clean interface, deep blue and cyan accents, ticket classification visualization, minimal, 16:9",
        "beforeAfter": {
          "before": "Типовые обращения классифицировали вручную, маршрут и ответ подбирались по памяти операторов.",
          "after": "AI ставит категорию и предлагает ответ, оператор подтверждает — SLA стабилизировался."
        }
      },
      "tags": [
        "medtech",
        "nlp",
        "mlops",
        "customer-support",
        "ai-routing"
      ],
      "relatedServiceSlugs": [
        "ai-integration-use-cases-mlops"
      ]
    },
    {
      "slug": "saas-devops-weekly-zero-downtime-releases",
      "title": "×4 частота релизов без простоя за 12 недель в SaaS‑стартапе",
      "industry": "SaaS",
      "problem": "SaaS-стартап быстро рос (25 000+ активных пользователей), но выпускал обновления раз в месяц, и почти каждый релиз сопровождался простоем 25–40 минут. Деплой выполняли вручную по чек-листам, часть шагов держалась «в голове» у одного-двух людей.\n\nПробовали автоматизировать скриптами, но окружения отличались, не было единых пайплайнов, а откат занимал много времени. Из‑за риска инцидентов команда откладывала релизы, а накопленные изменения повышали вероятность ошибок.\n\nНа кону были удержание клиентов и темп вывода фич: каждый простой бил по доверии и выручке, а редкие релизы тормозили рост и выполнение обязательств перед инвесторами.",
      "approach": "Мы провели аудит инфраструктуры и цепочки поставки изменений: сборка, тестирование, деплой, мониторинг, инциденты. Определили критичные сервисы и точки риска, описали целевую архитектуру и стандарты релизов.\n\nРассматривали два пути: уйти в управляемый PaaS или построить контейнерную платформу с контролем. Выбрали Kubernetes с постепенной миграцией: это дало гибкость, но без «большого взрыва» и остановки разработки.\n\nОграничения: небольшая команда (40+ сотрудников), нельзя было выделить отдельный SRE-отдел, а продукт должен был оставаться доступным 24/7. Поэтому делали изменения инкрементально и сразу закладывали наблюдаемость, runbook и безопасный откат.",
      "solution": "Настроили единый CI/CD: сборка, тесты, деплой по окружениям, проверки перед релизом. Контейнеризировали ключевые сервисы и привели окружения к единому стандарту.\n\nРазвернули Kubernetes-кластер и перевели деплой критичного сервиса на blue/green с быстрым откатом. Инфраструктуру описали как код (Terraform), добавили Helm-шаблоны для повторяемых релизов.\n\nПодняли наблюдаемость: метрики, логи, алёрты, трейсинг, плюс runbook для типовых инцидентов. Провели 2 совместных релиза с командой клиента и закрепили SLO/инцидент-ритм, чтобы платформа жила после проекта.",
      "stack": [
        "Kubernetes",
        "GitLab CI",
        "Terraform",
        "Helm",
        "Docker",
        "Prometheus",
        "Grafana",
        "Sentry"
      ],
      "timeline": "12 недель",
      "metrics": {
        "headline": "×4 частота релизов",
        "items": [
          {
            "label": "Частота релизов",
            "value": "1 раз/месяц → 1 раз/неделю",
            "description": "CI/CD и стандарты релизов убрали ручные шаги и снизили риск накопленных изменений."
          },
          {
            "label": "Простой при релизе",
            "value": "25–40 мин → 0 мин",
            "description": "Перешли на blue/green и контролируемый переключатель трафика."
          },
          {
            "label": "Время восстановления (MTTR)",
            "value": "2,5 ч → 45 мин",
            "description": "Наблюдаемость и runbook ускорили диагностику и откат."
          },
          {
            "label": "Успешность деплоев",
            "value": "86% → 97%",
            "description": "Добавили автоматические проверки и тесты перед выкатыванием в прод."
          }
        ],
        "testimonial": {
          "quote": "Релизы перестали быть ночным мероприятием: выкатываемся еженедельно и можем откатиться за минуты, если что-то пошло не так.",
          "author": "CTO, SaaS‑стартап (40+ чел.)"
        }
      },
      "assets": {
        "heroImage": "abstract SaaS DevOps pipeline dashboard, kubernetes cluster schematic, dark minimal UI, deep blue primary with cyan highlights, deployment flow, 16:9",
        "beforeAfter": {
          "before": "Релиз раз в месяц с ручным деплоем и 30 минут простоя.",
          "after": "CI/CD и blue/green: релиз раз в неделю без простоя и с быстрым откатом."
        }
      },
      "tags": [
        "saas",
        "kubernetes",
        "ci-cd",
        "devops",
        "zero-downtime"
      ],
      "relatedServiceSlugs": [
        "cloud-devops-ci-cd-platform"
      ]
    },
    {
      "slug": "manufacturing-iot-downtime-reduction",
      "title": "−4,5 п.п. простоев линии за 14 недель на перерабатывающем заводе",
      "industry": "Производство",
      "problem": "Завод по переработке работал круглосуточно, но незапланированные простои линии съедали около 12% рабочего времени. Остановка могла происходить 3–5 раз в день: перегрев узлов, вибрация, сбои в подаче сырья — причины фиксировали вручную и не всегда успевали разобраться.\n\nРаньше опирались на реактивный ремонт и журналы смен: данные по оборудованию либо не собирались, либо оставались в разрозненных системах. Даже когда датчики были, не было единого потока данных, алёртов и понятного «что делать дальше» для ремонтников.\n\nНа кону была производительность и безопасность: каждый час простоя — недовыпуск, переработки и риск порчи сырья. Нужно было получить раннее предупреждение и перейти к плановому обслуживанию без модернизации всей линии.",
      "approach": "Провели обследование критических узлов линии и выбрали пилотный контур: 18 двигателей и редукторов, которые чаще всего становились причиной остановок. Согласовали, какие параметры измеряем (вибрация, температура, ток), и как подключаемся с учётом требований OT-безопасности.\n\nРассматривали два пути: масштабная модернизация SCADA/АСУ ТП или «ретрофит» датчиков с edge-сбором данных и быстрым запуском мониторинга. Выбрали ретрофит: он давал эффект за недели и не требовал остановки производства.\n\nОграничения: доступ к оборудованию — только в короткие плановые окна, сеть OT сегментирована, а внешние подключения ограничены. Поэтому использовали edge-шлюз с буферизацией, локальное хранение и строгое разграничение доступа.",
      "solution": "Установили вибрационные и температурные датчики на выбранные узлы, подключили сигналы PLC по OPC UA и настроили сбор телеметрии через edge-шлюз. Сделали поток данных в хранилище временных рядов и построили дашборды для диспетчера и службы ремонта.\n\nНастроили алёрты по порогам и аномалиям (рост вибрации/температуры), добавили простую модель детекции деградации на исторических данных. Тревоги связали с регламентом реакции: кто получает уведомление, какие проверки делает, когда эскалирует.\n\nИнтегрировали события в процесс обслуживания: заявки в сервис-деск, чек-листы и runbook для типовых неисправностей. После запуска — обучение смен и контроль метрик 8 недель, чтобы закрепить переход от аварийного ремонта к плановому.",
      "stack": [
        "OPC UA",
        "MQTT",
        "Telegraf",
        "InfluxDB",
        "Grafana",
        "Node-RED",
        "Python"
      ],
      "timeline": "14 недель",
      "metrics": {
        "headline": "12% → 7,5% простоя",
        "items": [
          {
            "label": "Незапланированные простои линии",
            "value": "12% → 7,5%",
            "description": "Алёрты и предиктивные правила позволили устранять причины до остановки."
          },
          {
            "label": "Аварийные остановки",
            "value": "4,1/день → 2,3/день",
            "description": "Выявили повторяющиеся паттерны перегрева и вибрации по узлам."
          },
          {
            "label": "Время реакции на инцидент",
            "value": "35 мин → 12 мин",
            "description": "Диспетчер видит узел и причину в дашборде, есть понятный runbook действий."
          },
          {
            "label": "Предотвращённые отказы узлов",
            "value": "6 случаев за 2 месяца",
            "description": "Поймали деградацию подшипников и заменили узлы в плановое окно."
          }
        ],
        "testimonial": {
          "quote": "Мы впервые увидели, что линия «предупреждает» за часы до остановки. Это перевело ремонт из аварийного режима в плановый.",
          "author": "Главный инженер, завод по переработке (круглосуточная линия)"
        }
      },
      "assets": {
        "heroImage": "industrial IoT monitoring dashboard, factory processing line, sensors and data streams, dark clean UI, deep blue with cyan highlights, minimal, 16:9",
        "beforeAfter": {
          "before": "Простои фиксировали вручную, причины часто оставались неизвестными и повторялись.",
          "after": "Мониторинг и алёрты по узлам дали раннее предупреждение, простои снизились, ремонт стал плановым."
        }
      },
      "tags": [
        "manufacturing",
        "iot",
        "digital-twin",
        "predictive-maintenance",
        "real-time-monitoring"
      ],
      "relatedServiceSlugs": [
        "iot-digital-twins-pilot-platform"
      ]
    },
    {
      "slug": "ecommerce-single-source-of-truth",
      "title": "−55% времени на отчётность за 10 недель в e‑commerce (100K+ заказов)",
      "industry": "E-commerce",
      "problem": "E-commerce компания с объёмом 100 000+ заказов в месяц строила отчёты в Excel из разных источников: заказы, оплаты, маркетинг, логистика, возвраты. Метрики расходились: GMV, маржа и CAC считались по-разному в разных отделах, поэтому решения принимались «на глаз».\n\nРаньше пробовали внедрить BI, но без единого слоя данных и словаря метрик. В итоге в дашбордах отражались разные версии правды, качество данных не контролировалось, а ручная «склейка» в Excel оставалась ежедневной нормой.\n\nНа кону были деньги маркетинга и планирование запасов: неверная маржа и конверсия приводили к неправильным ставкам и закупкам. Нужно было быстро собрать «single source of truth», не трогая боевые системы и соблюдая требования по ПДн.",
      "approach": "Начали с аудита источников и договорились о едином словаре метрик: что такое заказ, когда он считается оплаченным, как считаем маржу и возвраты. Дальше спроектировали минимальный набор витрин под решения CEO/CMO/CFO.\n\nРассматривали вариант «просто стандартизировать Excel» и вариант построить DWH/Lakehouse с контролем качества и доступов. Выбрали платформенный подход: он закрывал проблему расхождений и масштабировался по мере роста объёма данных.\n\nОграничения: нельзя было создавать нагрузку на production, часть данных — персональная, а сроки ограничены квартальными планами. Поэтому сделали инкрементальные выгрузки, ролевой доступ и автоматические проверки качества на каждом шаге пайплайна.",
      "solution": "Построили слой загрузки данных из основных систем (заказы, платежи, маркетинг, логистика) и развели «сырые» и «очищенные» зоны. Собрали DWH в ClickHouse и настроили трансформации через dbt с версионированием.\n\nВвели data quality checks: контроль полноты, дублей, расхождений сумм, а также алёрты при ухудшении качества. Сделали витрины по продажам, маркетингу и логистике с едиными определениями метрик.\n\nСобрали BI-дашборды для руководства и команд, настроили ролевой доступ и аудит. Провели обучение аналитиков и передали runbook, чтобы платформа развивалась без зависимости от подрядчика.",
      "stack": [
        "ClickHouse",
        "Apache Airflow",
        "dbt",
        "Great Expectations",
        "Metabase",
        "PostgreSQL",
        "Docker"
      ],
      "timeline": "10 недель",
      "metrics": {
        "headline": "−55% времени на отчёты",
        "items": [
          {
            "label": "Время подготовки ежедневной отчётности",
            "value": "6 ч/день → 2,7 ч/день",
            "description": "Автоматизировали сбор и трансформации, убрали ручные «склейки» Excel."
          },
          {
            "label": "Расхождения в ключевых метриках",
            "value": "до 12% → <2%",
            "description": "Ввели единые определения и проверки качества на пайплайнах."
          },
          {
            "label": "Обновление дашбордов",
            "value": "1 раз/день → каждые 30 мин",
            "description": "Перешли на регулярные инкрементальные загрузки без нагрузки на production."
          },
          {
            "label": "Скорость решения по акциям и ставкам",
            "value": "2 дня → 4 часа",
            "description": "Маркетинг и закупки видят эффект почти в реальном времени и быстрее корректируют планы."
          }
        ],
        "testimonial": {
          "quote": "Главное — перестали спорить, какая цифра правильная: GMV и маржа считаются одинаково у всех. Отчёт теперь готовится автоматически и обновляется по расписанию.",
          "author": "CFO, e‑commerce (100K+ заказов/мес.)"
        }
      },
      "assets": {
        "heroImage": "abstract ecommerce analytics dashboard, clean minimal dark theme, deep blue primary with cyan accents, charts and funnels, data warehouse layers, 16:9",
        "beforeAfter": {
          "before": "Отчёты сводили в Excel, метрики расходились на двузначные проценты между отделами.",
          "after": "Единый слой данных и BI: метрики совпадают, обновление автоматизировано и прозрачно."
        }
      },
      "tags": [
        "ecommerce",
        "data-platform",
        "bi-dashboard",
        "clickhouse",
        "data-quality"
      ],
      "relatedServiceSlugs": [
        "data-analytics-platform-bi"
      ]
    }
  ]
}
